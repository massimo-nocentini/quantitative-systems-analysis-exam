% article example for classicthesis.sty
\documentclass[10pt,a4paper]{article}
\usepackage{lipsum}
\usepackage{url}
\usepackage[nochapters]{classicthesis} % nochapters
% \usepackage[showframe=true]{geometry}  
\usepackage{changepage}
\usepackage{graphicx}

\begin{document}
\title{\rmfamily\normalfont\spacedallcaps{Homework for Quantitative
    Systems Analysis Exam}} \author{\spacedlowsmallcaps{Massimo
    Nocentini}\\\spacedlowsmallcaps{ 5422207, Group 1}} \date{\today}
    
    \maketitle

    %% \noindent\lipsum[1] Just a test.\footnote{This is a footnote.}      
    \begin{abstract}
      This short article collects the work I did in order to support
      my Quantitative Systems Analysis exam. The goal is to study
      resources usage respect a collection of user profiles, each of
      them catch a way of using some applications of interest in
      different time windows. I performed some experiments collecting
      results in a OLAP ``star''-like relational schema in order to
      provide summaries for dimensions under study, such as bandwidth
      usage, network activity, CPU and memory consumption.
    \end{abstract}
       
    \tableofcontents
   
    % \section*{Introduction}

    % This homework aims to study resources usage respect a collection
    % of user profiles; we're mainly interested on network activities,
    % but we pair it with CPU and memory consumption. In order to
    % complete this work we take it apart, discussing the activity plan,
    % the instrumentation of the system used by different profiles, the
    % plan of experiments and finally data management and analysis of
    % results in the following sections. In the 
 
    \newpage
    \section{Analysis Plan}
    In this section I tackle the problem at hand describing the
    methodology used to perform the requested analysis, breaking the
    problem statement down in its major components. In the next
    section I'll describe them informally, leaving a precise
    description of their actions in \autoref{sec:plan-of-experiment}.


    \subsection{User profiles}
    A central concept is that of \emph{user profile} which abstract
    the behavior of a person using a computer. In this homework I've
    considered three user profiles: a \emph{landlady}, a
    \emph{computer scientist} and a \emph{Free Software Foundation
      supporter}. Informally, a landlady will use the computer for
    simple tasks such as checking emails, surfing the web and watch
    some YouTube videos; on the other hand a computer scientist will
    use the computer for writing \TeX documents, programming (in
    Smalltalk especially), collaborate with colleagues via instant
    messaging and checking its email account. Finally a FSF supporter
    just makes available its bandwidth supplying Ubuntu like distros
    via Torrent protocol.

    \subsection{Different workloads in different time windows}
    In order to study the user profiles I arranged that each one of
    them performs their activities repeating the same sequence of
    actions (with some minor variants) in three different time
    windows, namely in the morning, in the afternoon and in the
    evening. This allow us to characterize the same activity in
    different time windows with different workloads, in order to
    compare them in a quite real scenario.

    For example the \emph{landlady} user profile will do a quick check
    of emails in the morning, writing short messages to her friends in
    the afternoon while in the evening she replies to important mails
    with more care, preparing some drafts of her reply.  On the other
    side, the \emph{computer scientist} writes articles in the
    morning, programs in the middle of the day and reviews the morning
    work in the evening.  Finally, the \emph{FSF supporter} keeps its
    Bit Torrent client open for the entire day, switching the distros
    image supplied between morning, afternoon and evening.

    It is important to observe that each activity isn't performed in
    solitude, that is both email checking and programming could happen
    concurrently with other actions, for example searching some
    information on the web. This allow us to reify a scenario that is
    close to a real context, with the drawback of losing repetition
    among experiments execution.

    \subsection{Quantities to assess}
    We are interested on the resource consumption for each user
    profile during the three time windows as explained in the previous
    section. In particular we identifies the following quantities to
    be relevant for our analysis:
    \begin{description}
    \item[memory] the amount of free, buffered and cached memory;
    \item[disk IO] the blocks received from and sent to a block
      device;
    \item[CPU] the time spent running non-kernel code, kernel code and
      idle cycles;
    \item[network traffic] incoming and outgoing packets through a
      network interface, in particular we perform a complete packet
      sniffing in order to aggregate results as explained in
      \autoref{sec:data-management-result-analysis}.
    \end{description}


    \subsection{Factors and experiment conditioning}
    Since we would like to perform a monitoring of actions that
    actually happened, we fix as ``held-constant factors'' the use of
    applications as defined in \autoref{sec:plan-of-experiment}, while
    as ``allowed-to-vary factors'' every little deviations and
    ``micro'' actions from the main line experiment description. 

    This implies that experiment definition be described proposing an
    ``average'' behavior, allowing us to study the ``confirmation'' of
    measured quantities respect the same activity; the ``discovery''
    of patterns under slightly different operational conditions and
    ``stability'' of collected measure.

    \section{Measuring system instrumentation}
    To collect data about quantities of interest we've instrumented a
    laptop (from now on we call it the ``instrumented system'' or just
    ``system'') used by user profiles. Since our study is a kind of
    monitoring, we do not need to setup neither hardware/software
    probes nor failure injectors.

    The system have a Core i7 64bit Intel architecture, equipped with
    8 GB of RAM and powered by Ubuntu Linux 14.04 LTS distribution. In
    next sections we describe two tools we've used to collect
    measures.

    \subsection{vmstat} 
    To measure memory and CPU usage, we've used the \emph{vmstat}
    \cite{vmstat} command line tool: it is very lightweight and
    releases summary lines containing a super set of requested
    quantities. In particular the command we've used is the following:
\begin{verbatim}
vmstat <sec> -n -S M 
\end{verbatim}
    just a few explanations: every $sec$ seconds it drops a summary
    line on the standard output, ``-n'' doesn't repeat header lines
    periodically, ``-S M'' use Megabytes as measure unit for memory
    quantities. Usually we redirect the printed output to a file in
    order to post process data.

    While repeating experiments we change $sec$ respect to duration of
    the experiment at hand, that is for ``short'' experiments we need
    more granularity, hence we use $sec = 1$ (this is the case for
    \emph{experiment one} regarding \emph{landlady} user profile). On
    the other hand, we increase it for ``long'' experiment (this is
    the case for experiments regarding \emph{FSF supporter} user
    profile).

    \subsection{SNORT} 
    To measure network traffic we've used the \emph{SNORT} tool
    \cite{SNORT}, as required by homework assignment. We used
    \emph{SNORT} to save \emph{all} packages, in their complete
    structure (ie, including headers and payloads) saving them in
    binary files.  So, according the manual \cite{SNORT-manual}, we
    sniffed packages with the following command:
\begin{verbatim}
sudo snort -l <log-directory>/ -b
\end{verbatim}
    In order to analyze the collected data, we access informations
    saved binary file with the ``read'' feature provided by
    \emph{SNORT} itself, redirecting the output into a plain text file
    on which we run a ``cleaning'' \emph{sed}\cite{sed} script which
    transform it into another plain text file containing a row for
    each incoming/outgoing network package, hence no SNORT custom rule
    has been used. We value this approach because it allow us to have
    a \emph{complete} history of what happened, implementing the
    processing phase in Smalltalk as described in
    \autoref{sec:data-management-result-analysis}

    \newpage
    \section{Plan of experiments}
    \label{sec:plan-of-experiment}
    In this section we plan the experiments to gain insight about
    resource usage by different user profiles, describing experiments
    for each profile in a dedicated subsection and the motivations
    underlying each plan.

    \subsection{Landlady experiments plan}

    \subsubsection*{Experiments design }
    We created the following experiments in order to stress the
    activity of mail checking in particular, since this is the main
    task performed by our landlady user profile. Here we're not very
    interested on CPU and memory consumption, instead we remarkably
    vary the workloads to see changes in network traffic: especially,
    in \emph{experiment two} we pair writing short messages with
    watching a YouTube video, while in \emph{experiment three} we
    perform drafts preparation using Google web mail interface in
    order to study the impact of automatic saving policy.

    \emph{Experiment two} has an additional video watching action just
    to differentiate substantially from \emph{experiment one}, since
    our goal here is to compare data relative to the \emph{same}
    experiment collected in \emph{different} days, instead of
    comparing data relative to \emph{different} experiments collected
    in the \emph{same} day.

    \subsubsection*{Experiments descriptions}
    
    \begin{description}
    \item[experiment one] In the morning, the landlady open Mozilla
      Firefox browser, log in into her \emph{GMail} account, checks for
      new mail and log out after reading new messages, under the
      assumption that she reads at least two messages.
    \item[experiment two] In the afternoon, the landlady open Mozilla
      Firefox browser, log in into her \emph{GMail} account, checks
      for new mail and writes three short greetings to her
      friends. Here by ``short greetings'' we mean a message with at
      most 50 words.  While writing greetings, she watches her
      favorite YouTube video
      \footnote{\url{https://www.youtube.com/watch?v=yaaoEyWQ6eI}} for
      about two minutes at the 480p resolution.
    \item[experiment three] In the evening, the landlady open Mozilla
      Firefox browser, log in into her \emph{GMail} account, checks for
      new mail and prepare two draft for an important reply (assuming
      that at least one message received during the day deserve
      careful response). After saving the two draft, it randomly
      select one of those and send it. Here by ``important reply'' we
      mean a message with at least 120 words.
    \end{description}

    \newpage
    \subsection{Computer scientist experiments plan}

    \subsubsection*{Experiments design }
    We created the following experiments in order to observe resources
    consumption of multiple applications running at the same time, in
    particular \emph{experiments one} and \emph{four} focus on email
    checking while typesetting a document; \emph{experiment two} and
    \emph{three} focus on programming and video conference (partly
    instant messaging).

    In each experiment we couple an application that produce network
    traffic with one that consume CPU and memory, in order to have a
    profile quite opposite to that of \emph{landlady}. In this setting
    would make sense compare \emph{different} experiments given that
    they share the same activities.

    Particular interest can be pointed to \emph{experiment two} where
    we can study (small) network traffic during an instant messaging
    session between two peers while doing a computation intensive
    task. On the other hand in \emph{experiment three} we can observe
    (huge) network traffic generated by a Google Hangout video call
    while running a process with low priority.

    \subsubsection*{Experiments descriptions}
    
    \begin{description}
    \item[experiment one] In the early morning, the computer scientist
      open the Mozilla Firefox browser, logs in into his GMail account
      and do a quick check for new messages; we assume that he reads
      at least one message. Then, keeping the browser running, he
      writes a draft of at least 400 words using the Emacs text
      editor, compiles it using \TeX two times. Then he writes one
      message to his advisor with the compiled draft as
      attachment. Finally he logs out from Google web mail interface.
    \item[experiment two] At noon, the computer scientist do some
      hacking on his Pharo Smalltalk system, executing an intensive
      fluid dynamics analysis for a gas network. This analysis is
      repeated three times, each of one is 30 seconds longer. Waiting
      for analysis results, he talks with his colleague using Google
      Hangout directly from his Google web mail interface, sending and
      receiving at least 10 short phrases. Here by ``short phrase'' we
      mean a message with at most 10 words and we also assume that the
      login had already succeeded before starting the registering
      tools.
    \item[experiment three] In the afternoon, the computer scientist
      discuss the fluid analysis results obtained previously in a
      joint work through a video call using Google Hangout, via web
      interface using the Mozilla Firefox browser. While the
      conversation takes place the computer scientist performs one
      more time the fluid dynamics analysis. Here we assume that no
      textual instantaneous messages are exchanged, that the
      conversation is about 1'30'' longer and that the login had
      already succeeded and the call is already running before
      starting the registering tools.
    \end{description}

    \newpage
    \subsection{FSF supporter experiment plan}

    \subsubsection*{Experiments design }
    We created the following experiments in order to observe exactly
    one activity respect network traffic and disk IO. Both three
    experiments focus on the Transmission client for BitTorrent
    protocol supplying, without any limit on upstream bandwidth, three
    different Ubuntu-like distro images, one for each experiment.

    This settings allow a comparison of both the \emph{same}
    experiment among \emph{different} repetitions, both
    \emph{different} experiments respect the \emph{same} repetition.

    As a side note, this allow us to make a comparison of the traffic
    generated by the three Ubuntu-like distros.

    \subsubsection*{Experiments descriptions}
    
    \begin{description}
    \item[experiment one] In the morning, the FSF supporter opens the
      Bit Torrent Transmission client application in order to supply
      bandwidth providing latest Kubuntu Linux ISO image
      distribution. He doesn't set any bandwidth upload limit and
      keeps Transmission running for about two minutes.
    \item[experiment two] In the afternoon, the FSF supporter opens
      the Bit Torrent Transmission client application in order to
      supply bandwidth providing latest Ubuntu Linux ISO image
      distribution. He doesn't set any bandwidth upload limit and
      keeps Transmission running for about two minutes.
    \item[experiment three] In the evening, the FSF supporter opens
      the Bit Torrent Transmission client application in order to
      supply bandwidth providing latest Xubuntu Linux ISO image
      distribution. He doesn't set any bandwidth upload limit and
      keeps Transmission running for about two minutes.
    \end{description}

    \subsection{Execution methodology}

    Given an user profile, we repeat each experiment for five
    consecutive days, ensuring that each repetition happen within time
    window as required by experiment description, even though instant
    timings can varies among repetitions of the same experiment given
    two different days. In this work we refer to days in which
    experiment repetitions happen as \emph{Day one}, \emph{Day two},
    \emph{Day three}, \emph{Day four} and \emph{Day five},
    respectively.

    \newpage
    \section{Data management and analysis of results}
    \label{sec:data-management-result-analysis}

    In this section we'll describe the software architecture
    developed, dealing with it in the former part and we give our
    results interpretation in the latter one.

    \subsection{Software architecture}
    We developer a quite rich architecture to support our results
    interpretation. We would like to have an automatic tool that
    parses Snort log files, builds a comprehensive facts collection
    and supplies a fancy and flexible interface (programmatically, of
    course) to plot quantities of interests, exporting automatically
    in .eps files, and to aggregate measures into a summary, exporting
    automatically in \TeX tabular files. In the following we provide a
    brief description of this piece of work.

    \subsubsection{Pharo Smalltalk programming environment and TDD}
    n
    We implemented our code in Pharo Smalltalk, an image based
    programming environment. It allow a natural Test Driven
    Development style, so we strictly follow it. In what follows we
    refer to classes we've implemented and are available in the image,
    assuming the curious reader has set up the enviroment correctly
    (see \autoref{sec:appendix} for instructions).

    The class \emph{AQSLogFileTest} is the test suite we've created to
    drive our implementation: it contains test methods that assert on
    log file parsing, facts collecting, plotting and summary
    generation.

    \subsubsection{Snort log files parsing}

    To set the stage we need to handle binary Snort log file in a more
    comfortable way. We saved original Snort binary log files in the
    file system, organizing them hierarchically, by experiment number,
    user profile and day number, in the given order. Hence we process
    every log file by performing a depth-first visit, applying to each
    one of them a bash script which does some clean work, especially
    removing empty and separating lines, joining the rest toward the
    creation of new log file which has exactly one line per packet;
    here we report a chunk of
    the latter log (intentionally breaking page boundaries): 
    \begin{adjustwidth}{-4cm}{}
\begin{verbatim}
07/01-07:41:07.220098 92.104.129.98:6881 -> 192.168.0.4:51413 UDP TTL:45 TOS:0x0 ID:0 IpLen:20 DgmLen:129 DF
07/01-07:41:07.220190 192.168.0.4 -> 92.104.129.98 ICMP TTL:64 TOS:0xC0 ID:48370 IpLen:20 DgmLen:157 Type:3  Code:3  DESTINATION UNREACHABLE: PORT UNREACHABLE
07/01-07:41:07.277850 98.232.94.206:59805 -> 192.168.0.4:51413 TCP TTL:112 TOS:0x0 ID:14283 IpLen:20 DgmLen:48 DF ******S* Seq: 0x709F7FB  Ack: 0x0  Win: 0x2000  TcpLen: 28
07/01-07:41:07.277898 192.168.0.4:51413 -> 98.232.94.206:59805 TCP TTL:64 TOS:0x0 ID:41997 IpLen:20 DgmLen:40 DF ***A*R** Seq: 0x0  Ack: 0x709F7FC  Win: 0x0  TcpLen: 20
07/01-07:41:07.528356 91.65.105.145:51413 -> 192.168.0.4:51413 UDP TTL:47 TOS:0x0 ID:32138 IpLen:20 DgmLen:58 D
\end{verbatim}
    \end{adjustwidth}

    Performing this cleaning allow to handle files much shorter than
    the original ones produced by the ``read'' Snort feature: for
    example, one of our files shrinks from about 70000 to 14000 lines.

    \subsubsection{Building facts collection}

    Following \cite{bondavalli}, we introduced the concept of
    \emph{fact}, which collect all relevant information about events
    we care about. We do not use a database backend, preferring live
    objects to talk with. This allow an interactive session where the
    user can query the facts collection using all the pretty stuff
    supplied by Pharo Smalltalk to inspect and explore them, for
    example it is possible to filter facts using a predicate and use
    that selection programmatically. This methodology has the drawback
    to be slower respect a relational database engine, while gaining
    in flexibility.

    \subsubsection{Selecting facts toward actions}
    
    We use the facts collection to define a selection over it,
    reifying this concept in its own dedicate class
    \emph{FactsSelection}. This allow us to use the selection as a
    ``trampoline'' object \cite{weiher-ducasse} toward actions, from
    our point of view, plotting and summarizing. This allows
    extensibility since if a developer would like to use facts for a
    different goal, let say drawing histograms, it is required only to
    implement an action object able to receive a selection of
    facts. The two action classes relative to plotting and summarizing
    are \emph{FactsPlotter} and \emph{FactsSummary}, respectively. 

    It is possible to create a selection of fact providing a user
    profile, an experiment number and a day, additionally to an
    arbitrary predicate.

    \subsubsection{Plotting a facts selection}

    We supply one implementation for plotting a facts selection, with
    two main features: the one allow to scatter a quantity of interest
    agains time instant, the other allow to partition a quantity by
    another fact property, associating a different formatting for each
    group. We've used the former to scatter the CPU usage, while the
    latter to partition packet length by protocol packet membership,
    just for an use case. It is interesting to observe that both
    quantity selection both partitioning is implemented via an high
    order system, that is the user can select \emph{any} quantity
    using a declarative style, nothing is hardcoded for the problem at
    hand. From another point of view, if another Snort log file is
    under study, with different properties than ours, it is possible
    to use this plotting mechanisms just plugging in a block that
    selects the quantity it is required to scatter (of course, the
    data series format is customizable too). As plotting backend we
    lie on \emph{GnuPlot} \cite{gnuplot}.

    \subsubsection{Summarizing a facts selection}

    We supply one implementation for summarizing a facts selection,
    with a main feature to aggregate facts along some dimensions, an
    example can be see in tables reported in the following results
    section. Here the main issue is, given an user profile, build a
    matrix which has days on rows and experiments on columns. For each
    fact we assign it to a matrix cell, in order to post process each
    cell depending on its data content. If some data are available,
    the job is done by class \emph{DatafulCellStatus}, which interpret
    facts measures to supply the required aggregated values.

    As the case for plotting, if a user would like to aggregate
    respect different dimensions, it is required to specialize
    \emph{DatafulCellStatus} to have an output formatted as \TeX
    tabular environment.

    \subsubsection{Putting it all together}
    
    To make a long business short, we've implemented a set of classes
    whose responsibility is to interpret a log file, providing
    extension points to make a facts selection and using it for
    plotting against quantities of interest, which can be seen as a
    whole or as a partition; or for summarizing measures producing a
    \TeX file containing a tabular environment region, ready to be
    used as input file in an bigger document (as we're doing while
    writing this article). All the implementation abstracts from the
    problem at hand, being flexible to handle log files produced by
    different log producers.
    
    \newpage

    \subsection{Results commentary}

    In this section we'll report and explain obtained results. In
    order to do this, for each user profile we'll comment each
    experiment, reporting some scatters of interest (focusing on
    network traffic in particular) and histograms to show and
    interpreting a relation between what really happened with what it
    was supposed to be. 

    To not overwhelming the presentation, for each experiment we
    report first a scatter with the complete network traffic,
    immediately followed by a refined scatter filtering out packets
    without payload, while rest plots always refers to the latter
    situation.

    \subsubsection{On Landlady user profile}

    \subsubsection*{Experiment one}
    In
    \autoref{fig:landlady-user-profile-comprehensive-length-scatter}
    we report the scatter of the complete traffic, attaching
    comprehensive packet length on ordinates, against capturing
    timestamps on abscissa. We observe some background noise during
    all the registering time window, and we map the first spike to
    GMail web page request, the following traffic to performing login,
    the successive two spikes to reading two mails and the final one
    to logout, respectively. We report in
    \autoref{fig:landlady-user-profile-comprehensive-length-scatter-filtering-on-payload}
    a ``cleaned'' version of the same quantity, filtering out packets
    such that do not contain payload. In
    \autoref{fig:landlady-user-profile-exp-one-count-histogram} we
    aggregate traffic information in a histogram, counting exchanged
    packets per second, where it is possible to recognize the same
    pattern described for the scatter.

    Traffic is ruled by a connection oriented protocol, due to the
    strict majority of TCP packets as reported in
    \autoref{fig:landlady-user-profile-comprehensive-length-by-protocol},
    and is quite balanced respect packet direction as reported in
    \autoref{fig:landlady-user-profile-comprehensive-length-by-direction}.
    
    We do not report plots about CPU and memory usage since they are
    quite flat and do not catch significative events corresponding to
    user profile actions.

    \begin{figure}
      \centering
      \includegraphics{eps/plot-Landlady-ExperimentOne-DayTwo-quantity-comprehensive-length.eps}
      \caption{\emph{Landlady} user profile, experiment one:
        scatter of comprehensive length against captured timestamp in
        nanoseconds}
      \label{fig:landlady-user-profile-comprehensive-length-scatter}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics{eps/plot-Landlady-ExperimentOne-DayTwo-quantity-only-packets-with-payload-comprehensive-length.eps}
      \caption{\emph{Landlady} user profile, experiment one: scatter
        of comprehensive length, filtering out packets without
        payload}
      \label{fig:landlady-user-profile-comprehensive-length-scatter-filtering-on-payload}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics{eps/plot-Landlady-ExperimentOne-DayThree-aggregated-count-by-timestamp-interval.eps}
      \caption{\emph{Landlady} user profile, experiment one: histogram
        reporting number of packets in bins with length equals to 1
        second.}
      \label{fig:landlady-user-profile-exp-one-count-histogram}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics{eps/plot-Landlady-ExperimentOne-DayTwo-quantity-only-packets-with-payload-comprehensive-length-by-protocol.eps}
      \caption{\emph{Landlady} user profile, experiment one: scatter
        of comprehensive length, filtering out packets without payload
        and partitioning by protocol}
      \label{fig:landlady-user-profile-comprehensive-length-by-protocol}
    \end{figure}


    \begin{figure}
      \centering
      \includegraphics{eps/plot-Landlady-ExperimentOne-DayTwo-quantity-only-packets-with-payload-comprehensive-length-by-direction.eps}
      \caption{\emph{Landlady} user profile, experiment one: scatter
        of comprehensive length, filtering out packets without payload
        and partitioning by traffic direction}
      \label{fig:landlady-user-profile-comprehensive-length-by-direction}
    \end{figure}



    \subsubsection*{Experiment two}
    In
    \autoref{fig:landlady-user-profile-exp-two-comprehensive-length-scatter}
    and
    \autoref{fig:landlady-user-profile-exp-two-comprehensive-length-scatter-filtering-on-payload}
    we report the scatter of network traffic produced in experiment
    two, the former covers all packets instead the latter filter out
    packets without a payload. We can observe the presence of
    background noise due to sync and ack messages, but we're not able
    to deduce which spike correspond to which user profile action.  We
    suppose the initial traffic is due to YouTube video streaming,
    which produce many packets in the first part of the registering
    time window, while isn't possible to see the sending of three
    greetings from the scatter. On the other hand, histogram reported
    in \autoref{fig:landlady-user-profile-exp-two-count-histogram},
    allow to see three spikes but it isn't possible to associate them
    to packets for greetings or to video streaming since they appears
    to be too regular. Another interpretation is to associate greeting
    packets to three little spikes, each preceding a bigger one.

    This traffic is still connection oriented as shown in
    \autoref{fig:landlady-user-profile-exp-two-comprehensive-length-by-protocol}
    and quite balanced from route direction point of view as shown in
    \autoref{fig:landlady-user-profile-exp-two-comprehensive-length-by-direction}. In
    particular is more connection oriented than traffic produced by
    \emph{experiment one}, have a look at TCP percentages reported in
    the second column of \autoref{fig:landlady-user-profile};
    moreover, it is surprising to observe a similar number of packets
    per second (landlady checks mail very quickly).

    \begin{figure}
      \centering
      \includegraphics{eps/plot-Landlady-ExperimentTwo-DayThree-quantity-all-packets-comprehensive-length.eps}
      \caption{\emph{Landlady} user profile, experiment two: scatter
        of comprehensive length against captured timestamp in
        nanoseconds}
      \label{fig:landlady-user-profile-exp-two-comprehensive-length-scatter}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics{eps/plot-Landlady-ExperimentTwo-DayThree-quantity-only-packets-with-payload-comprehensive-length.eps}
      \caption{\emph{Landlady} user profile, experiment two: scatter
        of comprehensive length against captured timestamp in
        nanoseconds, filtering out packets without payload}
      \label{fig:landlady-user-profile-exp-two-comprehensive-length-scatter-filtering-on-payload}
    \end{figure}
    
    \begin{figure}
      \centering
      \includegraphics{eps/plot-Landlady-ExperimentTwo-DayFive-aggregated-count-by-timestamp-interval.eps}
      \caption{\emph{Landlady} user profile, experiment two: histogram
        reporting number of packets in bins with length equals to 1
        second.}
      \label{fig:landlady-user-profile-exp-two-count-histogram}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics{eps/plot-Landlady-ExperimentTwo-DayThree-quantity-only-packets-with-payload-comprehensive-length-by-protocol.eps}
      \caption{\emph{Landlady} user profile, experiment two: scatter
        of comprehensive length, filtering out packets without payload
        and partitioning by protocol}
      \label{fig:landlady-user-profile-exp-two-comprehensive-length-by-protocol}
    \end{figure}


    \begin{figure}
      \centering
      \includegraphics{eps/plot-Landlady-ExperimentTwo-DayThree-quantity-only-packets-with-payload-comprehensive-length-by-direction.eps}
      \caption{\emph{Landlady} user profile, experiment two: scatter
        of comprehensive length, filtering out packets without payload
        and partitioning by traffic direction}
      \label{fig:landlady-user-profile-exp-two-comprehensive-length-by-direction}
    \end{figure}



    \subsubsection*{Experiment three}
    In
    \autoref{fig:landlady-user-profile-exp-three-comprehensive-length-scatter}
    and
    \autoref{fig:landlady-user-profile-exp-three-comprehensive-length-scatter-filtering-on-payload}
    we report the scatter of network traffic produced in experiment
    three, the former covers all packets instead the latter filter out
    packets without a payload. Its quite clear the association with
    user actions: the first intense spike is for GMail login, then
    there are two ``blocks'' with sparse traffic, each corresponding
    to one draft preparation and the final spike is one mail
    sending. It is quite surprinsing that packet distribution is quite
    uniform after the initial login, as histogram reports in
    \autoref{fig:landlady-user-profile-exp-three-count-histogram}
    using bins of length 5 seconds each.

    This traffic is again connection oriented as shown in
    \autoref{fig:landlady-user-profile-exp-three-comprehensive-length-by-protocol}
    and length per packet in bytes is lower than those registered for
    \emph{experiment one} and \emph{two} and the number of packets per
    second is remarkably smaller due to a different sequence of
    actions, as reported in the third column of
    \autoref{fig:landlady-user-profile}.

    \begin{figure}
      \centering
      \includegraphics{eps/plot-Landlady-ExperimentThree-DayThree-quantity-all-packets-comprehensive-length.eps}
      \caption{\emph{Landlady} user profile, experiment three: scatter
        of comprehensive length against captured timestamp in
        nanoseconds}
      \label{fig:landlady-user-profile-exp-three-comprehensive-length-scatter}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics{eps/plot-Landlady-ExperimentThree-DayThree-quantity-only-packets-with-payload-comprehensive-length.eps}
      \caption{\emph{Landlady} user profile, experiment three: scatter
        of comprehensive length against captured timestamp in
        nanoseconds, filtering out packets without payload}
      \label{fig:landlady-user-profile-exp-three-comprehensive-length-scatter-filtering-on-payload}
    \end{figure}
    
    \begin{figure}
      \centering
      \includegraphics{eps/plot-Landlady-ExperimentThree-DayFive-aggregated-count-by-timestamp-interval.eps}
      \caption{\emph{Landlady} user profile, experiment three: histogram
        reporting number of packets in bins with length equals to 5
        seconds each.}
      \label{fig:landlady-user-profile-exp-three-count-histogram}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics{eps/plot-Landlady-ExperimentThree-DayThree-quantity-only-packets-with-payload-comprehensive-length-by-protocol.eps}
      \caption{\emph{Landlady} user profile, experiment three: scatter
        of comprehensive length, filtering out packets without payload
        and partitioning by protocol}
      \label{fig:landlady-user-profile-exp-three-comprehensive-length-by-protocol}
    \end{figure}


    % \begin{figure}
    %   \centering
    %   \includegraphics{eps/plot-Landlady-ExperimentThree-DayThree-quantity-only-packets-with-payload-comprehensive-length-by-direction.eps}
    %   \caption{\emph{Landlady} user profile, experiment three: scatter
    %     of comprehensive length, filtering out packets without payload
    %     and partitioning by traffic direction}
    %   \label{fig:landlady-user-profile-exp-three-comprehensive-length-by-direction}
    % \end{figure}

    \subsubsection*{Repeating experiments issues}
    
    We observe that experiments repeats with the same patterns, as
    proved by scatters, both in traffic distribution and by protocol
    partitioning. Looking at \autoref{fig:landlady-user-profile} we
    observe concordance among averaged quantities without any
    remarkable outsider. An odd case for \emph{experiment three} is
    reported in
    \autoref{fig:landlady-user-profile-exp-three-count-histogram-odd-case},
    where we observe a quantity of exchanged packets not present in
    other experiment's repetitions.

    \begin{figure}
      \centering
      \includegraphics{eps/plot-Landlady-ExperimentThree-DayTwo-aggregated-count-by-timestamp-interval.eps}
      \caption{\emph{Landlady} user profile: histogram reporting a bad
        case, with a spike not present in all the remaining histograms
        about experiment three.}
      \label{fig:landlady-user-profile-exp-three-count-histogram-odd-case}
    \end{figure}



    \subsubsection*{Measures' quality}
    Network traffic is quite accurate, as in scatters we've to resort
    to nanoseconds in order to see events. On the other hand, CPU and
    memory consumption didn't have the same accuracy, since
    \emph{vmstat} drops lines with a maximum rate of 1 second: this
    for \emph{experiment one} is useless since the entire time window
    duration is lower than a minute.
  

    \begin{table}
      \begin{adjustwidth}{-2cm}{}
        \input{summary-Landlady.tex}
      \end{adjustwidth}
      \caption{Summary table for \emph{landlady} user profile}
      \label{fig:landlady-user-profile}
    \end{table}

    \newpage

    \subsubsection{On Computer scientist user profile}
    For this profile we do not report many plots about network
    traffic, instead we move focus on CPU consumption in order to take
    into account the programming activity and Google Hangout video
    call. The complete set of plots is however available in the
    distributed package.
    
    \subsubsection*{Experiment one}
    In
    \autoref{fig:computer-scientist-user-profile-comprehensive-length-scatter-filtering-on-payload}
    we report the scatter of the complete traffic after removing
    background noise filtering protocol control messages: we map the
    first spike to GMail web page request, the following traffic to
    performing login, two thin spikes to reading two mails and the
    final one to attaching the compiled draft and sending mail,
    respectively.  In
    \autoref{fig:computer-scientist-user-profile-exp-one-count-histogram}
    we aggregate traffic information in a histogram, counting
    exchanged packets per second, where it is possible to recognize
    the same pattern described for the scatter: poor network activity.

    Traffic is ruled by a connection oriented protocol, due to the
    strict majority of TCP packets as reported in
    \autoref{fig:computer-scientist-user-profile-comprehensive-length-by-protocol},
    this confirm the fact obtained from \emph{experiment one} for
    \emph{landlady} profile that Google web mail is totally connection
    based, as we would expect.
    
    \autoref{fig:computer-scientist-user-profile-aggregate-cpu-idle-percentage}
    shows the two \TeX compilations, reporting two gaps of CPU
    \emph{idle} percentage in the first half of histogram.


    \begin{figure}
      \centering
      \includegraphics{eps/plot-ComputerScientist-ExperimentOne-DayTwo-quantity-only-packets-with-payload-comprehensive-length.eps}
      \caption{\emph{ComputerScientist} user profile, experiment one: scatter
        of comprehensive length, filtering out packets without
        payload}
      \label{fig:computer-scientist-user-profile-comprehensive-length-scatter-filtering-on-payload}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics{eps/plot-ComputerScientist-ExperimentOne-DayTwo-aggregated-count-by-timestamp-interval.eps}
      \caption{\emph{ComputerScientist} user profile, experiment one: histogram
        reporting number of packets in bins with length equals to 1
        second.}
      \label{fig:computer-scientist-user-profile-exp-one-count-histogram}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics{eps/plot-ComputerScientist-ExperimentOne-DayTwo-quantity-only-packets-with-payload-comprehensive-length-by-protocol.eps}
      \caption{\emph{ComputerScientist} user profile, experiment one: scatter
        of comprehensive length, filtering out packets without payload
        and partitioning by protocol}
      \label{fig:computer-scientist-user-profile-comprehensive-length-by-protocol}
    \end{figure}


    \begin{figure}
      \centering
      \includegraphics{eps/plot-ComputerScientist-ExperimentOne-DayThree-aggregated-average-of-cpu-idle-percentage-time-by-timestamp-interval.eps}
      \caption{\emph{ComputerScientist} user profile, experiment one:
        histogram about CPU consumption agains bins of length 5
        seconds each.}
      \label{fig:computer-scientist-user-profile-aggregate-cpu-idle-percentage}
    \end{figure}



    \subsubsection*{Experiment two}

    For this experiment we leave the plot about comprehensive network
    traffic, paying attention to some details. In
    \autoref{fig:computer-scientist-user-profile-experiment-two-comprehensive-length-scatter-filtering-on-payload-partitioned-by-direction}
    we report a scatter of the traffic of payloaded packets,
    partitioned by route direction: it is interesting that, since this
    traffic is generated only by textual instant messages, the
    incoming packets have a smaller length than outgoing packets,
    always respecting the assumption that both peers sent at most 10
    words in each message.

    Another interesting comparison arise by
    \autoref{fig:computer-scientist-user-profile-exp-two-count-histogram}
    and
    \autoref{fig:computer-scientist-user-profile-experiment-two-aggregate-cpu-idle-percentage}:
    those two histograms seems to mirror each other, in the sense that
    when there is network activity the fluid dynamic simulation is
    running and, on the contrary, when the simulation is suspended, no
    network traffic is present.

    We do not report the scatter partitioned by protocol since, using
    Google web mail interface, the majority of it belongs again to
    TCP.




    \begin{figure}
      \centering
      \includegraphics{eps/plot-ComputerScientist-ExperimentTwo-DayFive-quantity-only-packets-with-payload-comprehensive-length-by-direction.eps}
      \caption{\emph{ComputerScientist} user profile, experiment two:
        scatter of comprehensive length, filtering out packets without
        payload and partitioning by route direction}
      \label{fig:computer-scientist-user-profile-experiment-two-comprehensive-length-scatter-filtering-on-payload-partitioned-by-direction}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics{eps/plot-ComputerScientist-ExperimentTwo-DayFive-aggregated-count-by-timestamp-interval.eps}
      \caption{\emph{ComputerScientist} user profile, experiment two: histogram
        reporting number of packets in bins with length equals to 1
        second.}
      \label{fig:computer-scientist-user-profile-exp-two-count-histogram}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics{eps/plot-ComputerScientist-ExperimentTwo-DayFive-aggregated-average-of-cpu-idle-percentage-time-by-timestamp-interval.eps}
      \caption{\emph{ComputerScientist} user profile, experiment two:
        histogram about CPU consumption agains bins of length 5
        seconds each.}
      \label{fig:computer-scientist-user-profile-experiment-two-aggregate-cpu-idle-percentage}
    \end{figure}

    Looking at \autoref{fig:computer-scientist-user-profile}, we prove
    that both peer played according laws, since the percentage of
    incoming packets equals that of outgoing ones. Due to textual
    instant message exchanging only, the number of packets per seconds
    is very small, about 10 in average.



    \subsubsection*{Repeating experiments issues}
    
    We observe that experiments repeats with the same patterns, as
    proved by scatters, both in traffic distribution and by protocol
    partitioning. Looking at \autoref{fig:computer-scientist-user-profile} we
    observe concordance among averaged quantities without any
    remarkable outsider. 


    \subsubsection*{Measures' quality}
    Network traffic is quite accurate, as in scatters we've to resort
    to nanoseconds in order to see events. On the other hand, CPU and
    memory consumption didn't have the same accuracy, since
    \emph{vmstat} drops lines with a maximum rate of 1 second: this
    for \emph{experiment one} is useless since the entire time window
    duration is lower than a minute.
  
    \begin{table}
      \begin{adjustwidth}{-2cm}{}
        \input{summary-ComputerScientist.tex}    
      \end{adjustwidth}
      \caption{Summary table for \emph{computer scientist} user profile}
      \label{fig:computer-scientist-user-profile}
    \end{table}

    
    \subsubsection{On FSF supporter user profile}

    
    \subsubsection{Summary tables}


    \begin{table}
      \begin{adjustwidth}{-2cm}{}
        \input{summary-FSFSupporter.tex}
      \end{adjustwidth}
      \caption{Summary table for \emph{FSF supporter} user profile}
      \label{fig:FSF-supporter-user-profile}
    \end{table}




    



  %   \begin{table}
  %     \begin{adjustwidth}{-2cm}{}
  %     \centering
  %     \begin{tabular}{l| l| l | l| l }
  %       & Experiment 1& Experiment 2& Experiment 3& Experiment 4\\
  %       \hline
  %     Day 1 &
  %     \begin{tabular}{ l  r }
  %       cpu idle & 96.1 \% \\
  %       cpu user& 2\%  \\
  %       cpu kernel & 1.1 \% \\
  %       free mem & 4.3 GB \\
  %       \hline
  %       num packets & 9283 \\
  %       dim sum & 1.5 MB \\
  %       packets/sec & 6 \\
  %       interlap & 6 secs \\
  %       UDP & 6 \\
  %       TCP msgs & 6\% \\
  %       dim/msg & 146.3 Byte \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &      \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\       
  %     \end{tabular} \\
  %       \hline
  %     Day 1 &
  %     \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %       interlap & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &      \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\       
  %     \end{tabular} \\
  %       \hline
  %     Day 1 &
  %     \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %       interlap & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &      \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\       
  %     \end{tabular} \\
  %       \hline
  %     Day 1 &
  %     \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %       interlap & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &      \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\       
  %     \end{tabular} \\
  %       \hline
  %     Day 1 &
  %     \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %       interlap & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &      \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\       
  %     \end{tabular} \\
  %   \end{tabular}
  % \end{adjustwidth}
  % \end{table}
    \newpage

    \section{Appendix}
    \label{sec:appendix}

    \subsection{License}
\begin{verbatim}
The MIT License (MIT)

Copyright (c) 2014 Massimo Nocentini

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
\end{verbatim}

    \subsection{Project hosting}

    \subsection{Environment setup}

    

    \begin{thebibliography}{9}

    \bibitem{SNORT}
      SNORT Team,
      \url{https://www.snort.org/}.

    \bibitem{SNORT-manual}
      SNORT Team,
      \url{http://manual.snort.org/}.

    \bibitem{vmstat}
      Free Software Foundation,
      \url{http://www.freebsd.org/cgi/man.cgi?query=vmstat}.

    \bibitem{sed}
      Free Software Foundation,
      \url{http://www.freebsd.org/cgi/man.cgi?query=sed}

    \bibitem{gnuplot} Free Software
      Foundation,\url{http://www.gnuplot.info/}

    \bibitem{bondavalli} Andrea Bondavalli, Analisi quantitativa dei
      sistemi critici, March 2011, Progetto Leonardo, Esculapio
      Editore

    \bibitem{weiher-ducasse} Marcel Weiher and Stephane Ducasse,
      Higher Order Messaging, Dynamic Languages Symposium (DLS) '05,
      October 18, 2005, San Diego, CA, USA


    \end{thebibliography}
    % % bib stuff
    % \nocite{*}
    % \addtocontents{toc}{\protect\vspace{\beforebibskip}}
    % \addcontentsline{toc}{section}{\refname}    
    % \bibliographystyle{plain}
    % \bibliography{../Bibliography}
\end{document}
