% article example for classicthesis.sty
\documentclass[10pt,a4paper]{article}
\usepackage{lipsum}
\usepackage{url}
\usepackage[nochapters]{classicthesis} % nochapters
% \usepackage[showframe=true]{geometry}  
\usepackage{changepage}

\begin{document}
    \title{\rmfamily\normalfont\spacedallcaps{Homework for
        Quantitative Systems Analysis Exam}}
    \author{\spacedlowsmallcaps{Massimo Nocentini}} \date{\today}
    
    \maketitle

    %% \noindent\lipsum[1] Just a test.\footnote{This is a footnote.}      
    \begin{abstract}
      This short article collects the work I did in order to support
      my Quantitative Systems Analysis exam. The goal is to study
      resources usage respect a collection of user profiles, each of
      them catch a way of using some applications of interest in
      different time windows. I performed some experiments collecting
      results in a OLAP ``star''-like relational schema in order to
      provide summaries for dimensions under study, such as bandwidth
      usage, network activity, CPU and memory consumption.
    \end{abstract}
       
    \tableofcontents
   
    \section*{Introduction}

    This homework aims to study resources usage respect a collection
    of user profiles; we're mainly interested on network activities,
    but we pair it with CPU and memory consumption. In order to
    complete this work we take it apart, discussing the activity plan,
    the instrumentation of the system used by different profiles, the
    plan of experiments and finally data management and analysis of
    results in the following sections. In the 
 
    \newpage
    \section{Analysis Plan}
    In this section I tackle the problem at hand describing the
    methodology used to perform the requested analysis, breaking the
    problem statement down in its major components. In the next
    section I'll describe them informally, leaving a precise
    description of their actions in \autoref{sec:plan-of-experiment}.


    \subsection{User profiles}
    A central concept is that of \emph{user profile} which abstract
    the behavior of a person using a computer. In this homework I've
    considered three user profiles: a \emph{landlady}, a
    \emph{computer scientist} and a \emph{Free Software Foundation
      supporter}. Informally, a landlady will use the computer for
    simple tasks such as checking emails, surfing the web and watch
    some YouTube videos; on the other hand a computer scientist will
    use the computer for writing \TeX documents, programming (in
    Smalltalk especially), collaborate with colleagues via instant
    messaging and checking its email account. Finally a FSF supporter
    just makes available its bandwidth supplying Ubuntu like distros
    via Torrent protocol.

    \subsection{Different workloads in different time windows}
    In order to study the user profiles I arranged that each one of
    them performs their activities repeating the same sequence of
    actions (with some minor variants) in three different time
    windows, namely in the morning, in the afternoon and in the
    evening. This allow us to characterize the same activity in
    different time windows with different workloads, in order to
    compare them in a quite real scenario.

    For example the \emph{landlady} user profile will do a quick check
    of emails in the morning, writing short messages to her friends in
    the afternoon while in the evening she replies to important mails
    with more care, preparing some drafts of her reply.  On the other
    side, the \emph{computer scientist} writes articles in the
    morning, programs in the middle of the day and reviews the morning
    work in the evening.  Finally, the \emph{FSF supporter} keeps its
    Bit Torrent client open for the entire day, switching the distros
    image supplied between morning, afternoon and evening.

    It is important to observe that each activity isn't performed in
    solitude, that is both email checking and programming could happen
    concurrently with other actions, for example searching some
    information on the web. This allow us to reify a scenario that is
    close to a real context, with the drawback of losing repetition
    among experiments execution.

    \subsection{Quantities to assess}
    We are interested on the resource consumption for each user
    profile during the three time windows as explained in the previous
    section. In particular we identifies the following quantities to
    be relevant for our analysis:
    \begin{description}
    \item[memory] the amount of free, buffered and cached memory;
    \item[disk IO] the blocks received from and sent to a block
      device;
    \item[CPU] the time spent running non-kernel code, kernel code and
      idle cycles;
    \item[network traffic] incoming and outgoing packets through a
      network interface, in particular we perform a complete packet
      sniffing in order to aggregate results as explained in
      \autoref{sec:data-management-result-analysis}.
    \end{description}


    \subsection{Factors and experiment conditioning}
    Since we would like to perform a monitoring of actions that
    actually happened, we fix as ``held-constant factors'' the use of
    applications as defined in \autoref{sec:plan-of-experiment}, while
    as ``allowed-to-vary factors'' every little deviations and
    ``micro'' actions from the main line experiment description. 

    This implies that experiment definition be described proposing an
    ``average'' behavior, allowing us to study the ``confirmation'' of
    measured quantities respect the same activity; the ``discovery''
    of patterns under slightly different operational conditions and
    ``stability'' of collected measure.

    \section{Measuring system instrumentation}
    To collect data about quantities of interest we've instrumented a
    laptop (from now on we call it the ``instrumented system'' or just
    ``system'') used by user profiles. Since our study is a kind of
    monitoring, we do not need to setup neither hardware/software
    probes nor failure injectors.

    The system have a Core i7 64bit Intel architecture, equipped with
    8 GB of RAM and powered by Ubuntu Linux 14.04 LTS distribution. In
    next sections we describe two tools we've used to collect
    measures.

    \subsection{vmstat} 
    To measure memory and CPU usage, we've used the \emph{vmstat}
    \cite{vmstat} command line tool: it is very lightweight and
    releases summary lines containing a super set of requested
    quantities. In particular the command we've used is the following:
\begin{verbatim}
vmstat <sec> -n -S M 
\end{verbatim}
    just a few explanations: every $sec$ seconds it drops a summary
    line on the standard output, ``-n'' doesn't repeat header lines
    periodically, ``-S M'' use Megabytes as measure unit for memory
    quantities. Usually we redirect the printed output to a file in
    order to post process data.

    While repeating experiments we change $sec$ respect to duration of
    the experiment at hand, that is for ``short'' experiments we need
    more granularity, hence we use $sec = 1$ (this is the case for
    \emph{experiment one} regarding \emph{landlady} user profile). On
    the other hand, we increase it for ``long'' experiment (this is
    the case for experiments regarding \emph{FSF supporter} user
    profile).

    \subsection{SNORT} 
    To measure network traffic we've used the \emph{SNORT} tool
    \cite{SNORT}, as required by homework assignment. We used
    \emph{SNORT} to save \emph{all} packages, in their complete
    structure (ie, including headers and payloads) saving them in
    binary files.  So, according the manual \cite{SNORT-manual}, we
    sniffed packages with the following command:
\begin{verbatim}
sudo snort -l <log-directory>/ -b
\end{verbatim}
    In order to analyze the collected data, we access informations
    saved binary file with the ``read'' feature provided by
    \emph{SNORT} itself, redirecting the output into a plain text file
    on which we run a ``cleaning'' \emph{sed}\cite{sed} script which
    transform it into another plain text file containing a row for
    each incoming/outgoing network package, hence no SNORT custom rule
    has been used. We value this approach because it allow us to have
    a \emph{complete} history of what happened, implementing the
    processing phase in Smalltalk as described in
    \autoref{sec:data-management-result-analysis}

    \newpage
    \section{Plan of experiments}
    \label{sec:plan-of-experiment}
    In this section we plan the experiments to gain insight about
    resource usage by different user profiles, describing experiments
    for each profile in a dedicated subsection and the motivations
    underlying each plan.

    \subsection{Landlady experiments plan}

    \subsubsection*{Experiments design }
    We created the following experiments in order to stress the
    activity of mail checking in particular, since this is the main
    task performed by our landlady user profile. Here we're not very
    interested on CPU and memory consumption, instead we remarkably
    vary the workloads to see changes in network traffic: especially,
    in \emph{experiment two} we pair writing short messages with
    watching a YouTube video, while in \emph{experiment three} we
    perform drafts preparation using Google web mail interface in
    order to study the impact of automatic saving policy.

    \emph{Experiment two} has an additional video watching action just
    to differentiate substantially from \emph{experiment one}, since
    our goal here is to compare data relative to the \emph{same}
    experiment collected in \emph{different} days, instead of
    comparing data relative to \emph{different} experiments collected
    in the \emph{same} day.

    \subsubsection*{Experiments descriptions}
    
    \begin{description}
    \item[experiment one] In the morning, the landlady open Mozilla
      Firefox browser, log in into her \emph{GMail} account, checks for
      new mail and log out after reading new messages, under the
      assumption that she reads at least two messages.
    \item[experiment two] In the afternoon, the landlady open Mozilla
      Firefox browser, log in into her \emph{GMail} account, checks
      for new mail and writes three short greetings to her
      friends. Here by ``short greetings'' we mean a message with at
      most 50 words.  While writing greetings, she watches her
      favorite YouTube video
      \footnote{\url{https://www.youtube.com/watch?v=yaaoEyWQ6eI}} for
      about two minutes at the 480p resolution.
    \item[experiment three] In the evening, the landlady open Mozilla
      Firefox browser, log in into her \emph{GMail} account, checks for
      new mail and prepare two draft for an important reply (assuming
      that at least one message received during the day deserve
      careful response). After saving the two draft, it randomly
      select one of those and send it. Here by ``important reply'' we
      mean a message with at least 120 words.
    \end{description}

    \newpage
    \subsection{Computer scientist experiments plan}

    \subsubsection*{Experiments design }
    We created the following experiments in order to observe resources
    consumption of multiple applications running at the same time, in
    particular \emph{experiments one} and \emph{four} focus on email
    checking while typesetting a document; \emph{experiment two} and
    \emph{three} focus on programming and video conference (partly
    instant messaging).

    In each experiment we couple an application that produce network
    traffic with one that consume CPU and memory, in order to have a
    profile quite opposite to that of \emph{landlady}. In this setting
    would make sense compare \emph{different} experiments given that
    they share the same activities.

    Particular interest can be pointed to \emph{experiment two} where
    we can study (small) network traffic during an instant messaging
    session between two peers while doing a computation intensive
    task. On the other hand in \emph{experiment three} we can observe
    (huge) network traffic generated by a Google Hangout video call
    while running a process with low priority.

    \subsubsection*{Experiments descriptions}
    
    \begin{description}
    \item[experiment one] In the early morning, the computer scientist
      open the Mozilla Firefox browser, logs in into his GMail account
      and do a quick check for new messages; we assume that he reads
      at least one message. Then, keeping the browser running, he
      writes a draft of at least 400 words using the Emacs text
      editor, compiles it using \TeX three times. Then he writes one
      message to his advisor with the compiled draft as
      attachment. Finally he logs out from Google web mail interface.
    \item[experiment two] In the late morning, the computer scientist
      do some hacking on his Pharo Smalltalk system, executing an
      intensive fluid dynamics analysis for a gas network. This
      analysis is repeated three times, each of one is 20 seconds
      longer. Waiting for analysis results, he talks with his
      colleague using Google Hangout directly from his GMail web mail
      interface, sending and receiving at least 10 short phrases. Here
      by ``short phrase'' we mean a message with at most 10 words.
    \item[experiment three] In the afternoon, the computer scientist
      discuss the fluid analysis result obtained in the morning in a
      joint work through a video call using Google Hangout. The call
      has duration about one minute, during which he keeps the Pharo
      Smalltalk image running but he do not apply any change.
    \item[experiment four] In the evening, the computer scientist
      reviews the draft written in the early morning, using the Emacs
      text editor to skim through it and applies a spell checker. He
      at least recompile the document two times and after that he
      dispatch three mails from his Google web mail interface to his
      close friends. We assume that such minor modifications do not
      change significantly the compiled file dimension.
    \end{description}

    \newpage
    \subsection{FSF supporter experiment plan}

    \subsubsection*{Experiments design }
    We created the following experiments in order to observe exactly
    one activity respect network traffic and disk IO. Both three
    experiments focus on the Transmission client for BitTorrent
    protocol supplying, without any limit on upstream bandwidth, three
    different Ubuntu-like distro images, one for each experiment.

    This settings allow a comparison of both the \emph{same}
    experiment among \emph{different} repetitions, both
    \emph{different} experiments respect the \emph{same} repetition.

    As a side note, this allow us to make a comparison of the traffic
    generated by the three Ubuntu-like distros.

    \subsubsection*{Experiments descriptions}
    
    \begin{description}
    \item[experiment one] In the morning, the FSF supporter opens the
      Bit Torrent Transmission client application in order to supply
      bandwidth providing latest Kubuntu Linux ISO image
      distribution. He doesn't set any bandwidth upload limit and
      keeps Transmission running for about two minutes.
    \item[experiment two] In the afternoon, the FSF supporter opens
      the Bit Torrent Transmission client application in order to
      supply bandwidth providing latest Ubuntu Linux ISO image
      distribution. He doesn't set any bandwidth upload limit and
      keeps Transmission running for about two minutes.
    \item[experiment three] In the evening, the FSF supporter opens
      the Bit Torrent Transmission client application in order to
      supply bandwidth providing latest Xubuntu Linux ISO image
      distribution. He doesn't set any bandwidth upload limit and
      keeps Transmission running for about two minutes.
    \end{description}

    \subsection{Execution methodology}

    We repeat each experiment for each user profile for five
    consecutive days, ensuring that each repetition happen within time
    windows described by experiment, even though instant timings can
    varies among repetitions of the same experiment for the same user
    profile given two different days. In what follows we refer to days
    in which experiment repetition happen as \emph{Day one}, \emph{Day
      two}, \emph{Day three}, \emph{Day four} and \emph{Day five},
    respectively.

    \newpage
    \section{Data management and analysis of results}
    \label{sec:data-management-result-analysis}
    \lipsum[1]

    \input{summary-Landlady.tex}


  %   \begin{table}
  %     \begin{adjustwidth}{-2cm}{}
  %     \centering
  %     \begin{tabular}{l| l| l | l| l }
  %       & Experiment 1& Experiment 2& Experiment 3& Experiment 4\\
  %       \hline
  %     Day 1 &
  %     \begin{tabular}{ l  r }
  %       cpu idle & 96.1 \% \\
  %       cpu user& 2\%  \\
  %       cpu kernel & 1.1 \% \\
  %       free mem & 4.3 GB \\
  %       \hline
  %       num packets & 9283 \\
  %       dim sum & 1.5 MB \\
  %       packets/sec & 6 \\
  %       interlap & 6 secs \\
  %       UDP & 6 \\
  %       TCP msgs & 6\% \\
  %       dim/msg & 146.3 Byte \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &      \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\       
  %     \end{tabular} \\
  %       \hline
  %     Day 1 &
  %     \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %       interlap & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &      \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\       
  %     \end{tabular} \\
  %       \hline
  %     Day 1 &
  %     \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %       interlap & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &      \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\       
  %     \end{tabular} \\
  %       \hline
  %     Day 1 &
  %     \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %       interlap & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &      \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\       
  %     \end{tabular} \\
  %       \hline
  %     Day 1 &
  %     \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %       interlap & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &       \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\
  %     \end{tabular} &      \begin{tabular}{ l  r }
  %       cpu idle & 2  \\
  %       cpu user& 2  \\
  %       cpu kernel & 6 \\
  %       free mem & 6 \\
  %       num packets & 6 \\
  %       dim sum & 6 \\
  %       packets/sec & 6 \\       
  %     \end{tabular} \\
  %   \end{tabular}
  % \end{adjustwidth}
  % \end{table}
    \newpage

    \begin{thebibliography}{9}

    \bibitem{SNORT}
      SNORT Team,
      \url{https://www.snort.org/}.

    \bibitem{SNORT-manual}
      SNORT Team,
      \url{http://manual.snort.org/}.

    \bibitem{vmstat}
      Free Software Foundation,
      \url{http://www.freebsd.org/cgi/man.cgi?query=vmstat}.

    \bibitem{sed}
      Free Software Foundation,
      \url{http://www.freebsd.org/cgi/man.cgi?query=sed}
    \end{thebibliography}
    % % bib stuff
    % \nocite{*}
    % \addtocontents{toc}{\protect\vspace{\beforebibskip}}
    % \addcontentsline{toc}{section}{\refname}    
    % \bibliographystyle{plain}
    % \bibliography{../Bibliography}
\end{document}
